{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "import holidays\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.losses import Huber\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ],
   "id": "a2fa202e3185003a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def upload_data():\n",
    "    data_path = str(Path.cwd().parent) + \"\\\\Data\\\\EPC\\\\Power Consumption Data.csv\"\n",
    "\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    df = df[df[\"real_consumption\"] > 0]\n",
    "    df = df[df['real_consumption'] <= df['real_consumption'].mean() + 4 * df['real_consumption'].std()]\n",
    "\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df = df.sort_values(by='time',ascending=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def data_metrics(data, real, predicted):\n",
    "\n",
    "    y_true = data[real]\n",
    "    y_pred = data[predicted]\n",
    "\n",
    "\n",
    "    def r2_score_tf(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Computes the R² (coefficient of determination) score in TensorFlow.\n",
    "        \n",
    "        Parameters:\n",
    "        y_true : Tensor\n",
    "            Ground truth values.\n",
    "        y_pred : Tensor\n",
    "            Predicted values.\n",
    "    \n",
    "        Returns:\n",
    "        Tensor\n",
    "            The R² score.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "    \n",
    "        unexplained_error = tf.reduce_sum(tf.square(y_true - y_pred))  # SSE\n",
    "        total_error = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))  # SST\n",
    "    \n",
    "        r_squared = 1.0 - (unexplained_error / (total_error + tf.keras.backend.epsilon()))  # Prevent division by zero\n",
    "        return r_squared\n",
    "\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae = tf.keras.losses.MeanAbsoluteError()(y_true, y_pred).numpy()\n",
    "    mse = tf.keras.losses.MeanSquaredError()(y_true, y_pred).numpy()\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score_tf(y_true, y_pred)\n",
    "\n",
    "\n",
    "    # MAE (Mean Absolute Error):\n",
    "    # Lower values are better; good MAE depends on the scale of 'real_consumption'.\n",
    "    # As a rule of thumb, MAE should be significantly smaller than the mean of the target variable.\n",
    "    # Lower is better. Ideally, MAE should be much less than the average value of y_true.\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "    # MSE (Mean Squared Error):\n",
    "    # Similar to MAE but penalizes large errors more heavily. A smaller MSE is better.\n",
    "    # Compare MSE to the variance of 'real_consumption' for context.\n",
    "    # Lower is better. MSE should ideally be close to zero relative to the variance of y_true.\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    # RMSE (Root Mean Squared Error):\n",
    "    # RMSE is the square root of MSE and is in the same units as 'real_consumption'.\n",
    "    # A good RMSE is often close to the standard deviation of 'real_consumption'.\n",
    "    # Lower is better. RMSE should be comparable to or less than the standard deviation of y_true.\"\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    # R² (Coefficient of Determination):\n",
    "    # R² measures how well the predictions explain the variability of the data.\n",
    "    # Values close to 1.0 are excellent, indicating the model explains most of the variance.\n",
    "    # Negative values indicate poor fit.\n",
    "    # Closer to 1.0 is better. Values > 0.7 are generally good; < 0.5 indicates underfitting.\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "def feature_engineering(data):\n",
    "\n",
    "    # Extracting basic time-based features\n",
    "    data['hour'] = data['time'].dt.hour  # Hour of the day\n",
    "    data['minute'] = data['time'].dt.minute  # Minute\n",
    "    data['day_of_week'] = data['time'].dt.dayofweek  # Day of the week (0=Monday, 6=Sunday)\n",
    "    data['is_weekend'] = data['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)  # Weekend flag\n",
    "    data['day_of_month'] = data['time'].dt.day\n",
    "    data['week_of_year'] = data['time'].dt.isocalendar().week\n",
    "    data['month'] = data['time'].dt.month\n",
    "    data['quarter'] = data['time'].dt.quarter\n",
    "    data['year'] = data['time'].dt.year\n",
    "\n",
    "\n",
    "    # Generate lag features for temporal dependency modeling\n",
    "    for lag in range(1, 5):  # Create lag features for the past 4 time steps\n",
    "        data[f'lag_{lag}'] = data['real_consumption'].shift(lag)\n",
    "\n",
    "\n",
    "    # Generate exponential moving averages\n",
    "    for span in [3, 5]:  # Spans of size 3, 5, and 7\n",
    "        data[f'ema_{span}'] = data['real_consumption'].ewm(span=span, adjust=False).mean()\n",
    "\n",
    "    # Rolling average over a longer period (e.g., weekly and monthly moving averages)\n",
    "    data['weekly_avg'] = data['real_consumption'].rolling(window=7*24*20, min_periods=1).mean()  # Weekly moving avg\n",
    "    data['monthly_avg'] = data['real_consumption'].rolling(window=30*24*20, min_periods=1).mean()  # Monthly moving avg\n",
    "\n",
    "\n",
    "    # Percentage change in real consumption\n",
    "    data['pct_change'] = data['real_consumption'].pct_change()\n",
    "\n",
    "    data['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)  # Cyclic hour feature (sine)\n",
    "    data['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)  # Cyclic hour feature (cosine)\n",
    "\n",
    "    data['day_of_week_sin'] = np.sin(2 * np.pi * data['day_of_week'] / 7)\n",
    "    data['day_of_week_cos'] = np.cos(2 * np.pi * data['day_of_week'] / 7)\n",
    "\n",
    "    data['month_sin'] = np.sin(2 * np.pi * data['month'] / 12)\n",
    "    data['month_cos'] = np.cos(2 * np.pi * data['month'] / 12)\n",
    "\n",
    "    data['week_of_year_sin'] = np.sin(2 * np.pi * data['week_of_year'] / 52)\n",
    "    data['week_of_year_cos'] = np.cos(2 * np.pi * data['week_of_year'] / 52)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Get Georgia holidays for all years in the dataset\n",
    "    georgia_holidays = holidays.Georgia(years=range(data[\"year\"].min(), data[\"year\"].max() + 1))\n",
    "\n",
    "    data[\"date\"] = data[\"time\"].dt.date\n",
    "\n",
    "    # Create holiday feature (1 if it's a holiday, 0 otherwise)\n",
    "    data['is_holiday'] = data[\"date\"].map(lambda x: 1 if x in georgia_holidays else 0)\n",
    "\n",
    "    # Add features for the day before and after a holiday\n",
    "    data['is_day_before_holiday'] = data[\"date\"].map(lambda x: 1 if (x - pd.Timedelta(days=1)) in georgia_holidays else 0)\n",
    "    data['is_day_after_holiday'] = data[\"date\"].map(lambda x: 1 if (x + pd.Timedelta(days=1)) in georgia_holidays else 0)\n",
    "\n",
    "\n",
    "\n",
    "    return  data\n",
    "\n"
   ],
   "id": "5a8ca2c473c7e3c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = upload_data()\n",
    "\n",
    "data_metrics(data=df, real=\"real_consumption\", predicted=\"predicted_consumption\")\n",
    "\n",
    "df = feature_engineering(df)\n"
   ],
   "id": "221244da3a5ee410",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9a75d18307b88df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.index = pd.to_datetime(df['time'], format='%d.%m.%Y %H:%M:%S')\n",
    "# temp = df[['real_consumption',\"hour\",\"weekly_avg\",\"monthly_avg\",\"hour_sin\",\n",
    "# \"hour_cos\",\"lag_1\",\"ema_3\",\"month_sin\",\"month_cos\",\"week_of_year_sin\",\"week_of_year_cos\"]]\n",
    "\n",
    "temp = df[['real_consumption',\"hour\",\"weekly_avg\",\"monthly_avg\",\"ema_3\",\"month\",\"week_of_year\",\"day_of_month\",\"is_weekend\",\"day_of_week\"]]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "temp = pd.DataFrame(scaler.fit_transform(temp), columns=temp.columns)\n",
    "temp.index = pd.to_datetime(df['time'], format='%d.%m.%Y %H:%M:%S')"
   ],
   "id": "fbea4b7ff427582a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# [[[1], [2], [3], [4], [5]]] [6]\n",
    "# [[[2], [3], [4], [5], [6]]] [7]\n",
    "# [[[3], [4], [5], [6], [7]]] [8]\n",
    "\n",
    "def df_to_X_y(df, window_size=5):\n",
    "    df_as_np = df.to_numpy().astype(\"float32\")  # Convert to float32\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(len(df_as_np)-window_size):\n",
    "        row = df_as_np[i:i+window_size]  # Past `window_size` rows as input\n",
    "        X.append(row)\n",
    "        label = df_as_np[i+window_size, 0]  # Target: `real_consumption`\n",
    "        y.append(label)\n",
    "\n",
    "    return np.array(X, dtype=\"float32\"), np.array(y, dtype=\"float32\")  # Convert to float32\n",
    "\n"
   ],
   "id": "e523bfbe2a7649f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "WINDOW_SIZE = 20\n",
    "X1, y1 = df_to_X_y(temp, WINDOW_SIZE)\n",
    "X1.shape, y1.shape"
   ],
   "id": "96046be896c8da13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train1, y_train1 = X1[:600000], y1[:600000]\n",
    "X_val1, y_val1 = X1[600000:650000], y1[600000:650000]\n",
    "X_test1, y_test1 = X1[650000:], y1[650000:]\n",
    "X_train1.shape, y_train1.shape, X_val1.shape, y_val1.shape, X_test1.shape, y_test1.shape"
   ],
   "id": "95cc7235efb0f37d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = Sequential([\n",
    "    InputLayer((X1.shape[1], X1.shape[2])),  # Updated input shape\n",
    "    LSTM(64, return_sequences=True),  # First LSTM layer\n",
    "    LSTM(32),  # Second LSTM layer\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='linear')  # Predicting `real_consumption`\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=Huber(delta=1.0),\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    metrics=[RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 10\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train1, y_train1)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_val1, y_val1)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Train with ModelCheckpoint & EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint_path = str(Path.cwd().parent / \"Data\" / \"best_model.keras\")\n",
    "\n",
    "cp1 = ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, monitor=\"val_loss\", verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[cp1, early_stopping]\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "147409187b9e1505",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T10:50:28.145382Z",
     "start_time": "2025-03-07T10:47:04.448383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model1 = load_model(checkpoint_path)\n",
    "\n",
    "train_predictions = model1.predict(X_train1).flatten()\n",
    "train_results = pd.DataFrame(data={'Train Predictions':train_predictions, 'Actuals':y_train1})\n",
    "\n",
    "# val_predictions = model1.predict(X_val1).flatten()\n",
    "# val_results = pd.DataFrame(data={'Val Predictions':val_predictions, 'Actuals':y_val1})\n",
    "\n",
    "test_predictions = model1.predict(X_test1).flatten()\n",
    "test_results = pd.DataFrame(data={'Test Predictions':test_predictions, 'Actuals':y_test1})\n"
   ],
   "id": "9989dcc18dad1ae9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m18750/18750\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m174s\u001B[0m 9ms/step\n",
      "\u001B[1m1823/1823\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 11ms/step\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T10:50:53.948705Z",
     "start_time": "2025-03-07T10:50:53.928687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "min_real = df['real_consumption'].min()\n",
    "max_real = df['real_consumption'].max()\n",
    "\n",
    "train_results['real_consumption'] = train_results['Actuals'] * (max_real - min_real) + min_real\n",
    "train_results['train_predictions'] = train_results['Train Predictions'] * (max_real - min_real) + min_real"
   ],
   "id": "48e77343dc0fd710",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T10:50:59.699158Z",
     "start_time": "2025-03-07T10:50:59.682029Z"
    }
   },
   "cell_type": "code",
   "source": "train_results",
   "id": "8766ed9474ec04c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Train Predictions   Actuals  real_consumption_  real_consumption  \\\n",
       "0                0.446332  0.416972                NaN       1546.359375   \n",
       "1                0.447978  0.422939                NaN       1557.565063   \n",
       "2                0.449355  0.423951                NaN       1559.466187   \n",
       "3                0.450434  0.422593                NaN       1556.916016   \n",
       "4                0.451145  0.423446                NaN       1558.518433   \n",
       "...                   ...       ...                ...               ...   \n",
       "599995           0.467379  0.449919                NaN       1608.236084   \n",
       "599996           0.465150  0.438581                NaN       1586.942505   \n",
       "599997           0.463728  0.425551                NaN       1562.470581   \n",
       "599998           0.462028  0.414009                NaN       1540.793823   \n",
       "599999           0.459928  0.435154                NaN       1580.505615   \n",
       "\n",
       "        train_predictions  \n",
       "0             1601.499268  \n",
       "1             1604.591553  \n",
       "2             1607.176514  \n",
       "3             1609.204102  \n",
       "4             1610.538818  \n",
       "...                   ...  \n",
       "599995        1641.027466  \n",
       "599996        1636.840820  \n",
       "599997        1634.169434  \n",
       "599998        1630.978516  \n",
       "599999        1627.033936  \n",
       "\n",
       "[600000 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Predictions</th>\n",
       "      <th>Actuals</th>\n",
       "      <th>real_consumption_</th>\n",
       "      <th>real_consumption</th>\n",
       "      <th>train_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.446332</td>\n",
       "      <td>0.416972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1546.359375</td>\n",
       "      <td>1601.499268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.447978</td>\n",
       "      <td>0.422939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1557.565063</td>\n",
       "      <td>1604.591553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.449355</td>\n",
       "      <td>0.423951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1559.466187</td>\n",
       "      <td>1607.176514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.450434</td>\n",
       "      <td>0.422593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1556.916016</td>\n",
       "      <td>1609.204102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.451145</td>\n",
       "      <td>0.423446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1558.518433</td>\n",
       "      <td>1610.538818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>0.467379</td>\n",
       "      <td>0.449919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1608.236084</td>\n",
       "      <td>1641.027466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>0.465150</td>\n",
       "      <td>0.438581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1586.942505</td>\n",
       "      <td>1636.840820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>0.463728</td>\n",
       "      <td>0.425551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1562.470581</td>\n",
       "      <td>1634.169434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>0.462028</td>\n",
       "      <td>0.414009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1540.793823</td>\n",
       "      <td>1630.978516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599999</th>\n",
       "      <td>0.459928</td>\n",
       "      <td>0.435154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1580.505615</td>\n",
       "      <td>1627.033936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600000 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T10:51:49.141758Z",
     "start_time": "2025-03-07T10:51:49.113312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_metrics(data=train_results, real=\"Actuals\", predicted=\"Train Predictions\")\n",
    "\n",
    "data_metrics(data=train_results, real=\"real_consumption\", predicted=\"train_predictions\")"
   ],
   "id": "97a81b223a2498ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.0449\n",
      "MSE: 0.0035\n",
      "RMSE: 0.0590\n",
      "R²: 0.8263\n",
      "MAE: 84.3250\n",
      "MSE: 12259.0615\n",
      "RMSE: 110.7206\n",
      "R²: 0.8263\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "abf6c92900ca37b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

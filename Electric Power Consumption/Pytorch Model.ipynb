{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-07T05:45:40.104052Z",
     "start_time": "2025-03-07T05:45:33.336726Z"
    }
   },
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime, timedelta\n",
    "from xgboost import XGBRegressor\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "def upload_data():\n",
    "    data_path = str(Path.cwd().parent) + \"\\\\Data\\\\EPC\\\\Power Consumption Data.csv\"\n",
    "    \n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    df = df[df[\"real_consumption\"] > 0]\n",
    "    df = df[df['real_consumption'] <= df['real_consumption'].mean() + 4 * df['real_consumption'].std()]\n",
    "    \n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df = df.sort_values(by='time',ascending=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def data_metrics(data, real, predicted):\n",
    "\n",
    "    y_true = data[real]\n",
    "    y_pred = data[predicted]\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "    # MAE (Mean Absolute Error):\n",
    "    # Lower values are better; good MAE depends on the scale of 'real_consumption'.\n",
    "    # As a rule of thumb, MAE should be significantly smaller than the mean of the target variable.\n",
    "    # Lower is better. Ideally, MAE should be much less than the average value of y_true.\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "    # MSE (Mean Squared Error):\n",
    "    # Similar to MAE but penalizes large errors more heavily. A smaller MSE is better.\n",
    "    # Compare MSE to the variance of 'real_consumption' for context.\n",
    "    # Lower is better. MSE should ideally be close to zero relative to the variance of y_true.\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    # RMSE (Root Mean Squared Error):\n",
    "    # RMSE is the square root of MSE and is in the same units as 'real_consumption'.\n",
    "    # A good RMSE is often close to the standard deviation of 'real_consumption'.\n",
    "    # Lower is better. RMSE should be comparable to or less than the standard deviation of y_true.\"\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    # R² (Coefficient of Determination):\n",
    "    # R² measures how well the predictions explain the variability of the data.\n",
    "    # Values close to 1.0 are excellent, indicating the model explains most of the variance.\n",
    "    # Negative values indicate poor fit.\n",
    "    # Closer to 1.0 is better. Values > 0.7 are generally good; < 0.5 indicates underfitting.\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "def feature_engineering(data):\n",
    "\n",
    "    # Extracting basic time-based features\n",
    "    data['hour'] = data['time'].dt.hour  # Hour of the day\n",
    "    data['minute'] = data['time'].dt.minute  # Minute\n",
    "    data['day_of_week'] = data['time'].dt.dayofweek  # Day of the week (0=Monday, 6=Sunday)\n",
    "    data['is_weekend'] = data['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)  # Weekend flag\n",
    "    data['day_of_month'] = data['time'].dt.day\n",
    "    data['week_of_year'] = data['time'].dt.isocalendar().week\n",
    "    data['month'] = data['time'].dt.month\n",
    "    data['quarter'] = data['time'].dt.quarter\n",
    "    data['year'] = data['time'].dt.year\n",
    "\n",
    "\n",
    "    # Generate lag features for temporal dependency modeling\n",
    "    for lag in range(1, 5):  # Create lag features for the past 4 time steps\n",
    "        data[f'lag_{lag}'] = data['real_consumption'].shift(lag)\n",
    "\n",
    "\n",
    "    # Generate exponential moving averages\n",
    "    for span in [3, 5]:  # Spans of size 3, 5, and 7\n",
    "        data[f'ema_{span}'] = data['real_consumption'].ewm(span=span, adjust=False).mean()\n",
    "\n",
    "    # Rolling average over a longer period (e.g., weekly and monthly moving averages)\n",
    "    data['weekly_avg'] = data['real_consumption'].rolling(window=7*24*20, min_periods=1).mean()  # Weekly moving avg\n",
    "    data['monthly_avg'] = data['real_consumption'].rolling(window=30*24*20, min_periods=1).mean()  # Monthly moving avg\n",
    "\n",
    "\n",
    "# Percentage change in real consumption\n",
    "    data['pct_change'] = data['real_consumption'].pct_change()\n",
    "\n",
    "    data['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)  # Cyclic hour feature (sine)\n",
    "    data['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)  # Cyclic hour feature (cosine)\n",
    " \n",
    "    data['day_of_week_sin'] = np.sin(2 * np.pi * data['day_of_week'] / 7)\n",
    "    data['day_of_week_cos'] = np.cos(2 * np.pi * data['day_of_week'] / 7)\n",
    "    \n",
    "    data['month_sin'] = np.sin(2 * np.pi * data['month'] / 12)\n",
    "    data['month_cos'] = np.cos(2 * np.pi * data['month'] / 12)\n",
    "    \n",
    "    data['week_of_year_sin'] = np.sin(2 * np.pi * data['week_of_year'] / 52)\n",
    "    data['week_of_year_cos'] = np.cos(2 * np.pi * data['week_of_year'] / 52)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Get Georgia holidays for all years in the dataset\n",
    "    georgia_holidays = holidays.Georgia(years=range(data[\"year\"].min(), data[\"year\"].max() + 1))\n",
    "\n",
    "    data[\"date\"] = data[\"time\"].dt.date\n",
    "    \n",
    "    # Create holiday feature (1 if it's a holiday, 0 otherwise)\n",
    "    data['is_holiday'] = data[\"date\"].map(lambda x: 1 if x in georgia_holidays else 0)\n",
    "    \n",
    "    # Add features for the day before and after a holiday\n",
    "    data['is_day_before_holiday'] = data[\"date\"].map(lambda x: 1 if (x - pd.Timedelta(days=1)) in georgia_holidays else 0)\n",
    "    data['is_day_after_holiday'] = data[\"date\"].map(lambda x: 1 if (x + pd.Timedelta(days=1)) in georgia_holidays else 0)\n",
    "\n",
    "\n",
    "\n",
    "    return  data\n",
    "\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T05:45:40.147071Z",
     "start_time": "2025-03-07T05:45:40.118148Z"
    }
   },
   "id": "6b1e95fb5f8b736d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "df = upload_data()\n",
    "\n",
    "data_metrics(data=df, real=\"real_consumption\", predicted=\"predicted_consumption\")\n",
    "\n",
    "df = feature_engineering(df)[[\"time\",\"real_consumption\",\"predicted_consumption\"]]\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T05:45:53.455576Z",
     "start_time": "2025-03-07T05:45:40.279949Z"
    }
   },
   "id": "5c638f67c9e70eca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 56.7256\n",
      "MSE: 5824.3342\n",
      "RMSE: 76.3173\n",
      "R²: 0.9176\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T05:45:53.513733Z",
     "start_time": "2025-03-07T05:45:53.477349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler = MinMaxScaler()\n",
    "df[\"real_consumption\"] = scaler.fit_transform(df[\"real_consumption\"].values.reshape(-1, 1))\n",
    "df[\"predicted_consumption\"] = scaler.fit_transform(df[\"predicted_consumption\"].values.reshape(-1, 1))"
   ],
   "id": "839af60ffab8fd66",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T05:45:55.588076Z",
     "start_time": "2025-03-07T05:45:53.535295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEQ_LEN = 120  # Use past 12 hours (240 steps, 3-minute intervals)\n",
    "PRED_LEN = 120  # Predict next 12 hours\n",
    "\n",
    "def create_sequences(data, seq_len, pred_len):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_len - pred_len):\n",
    "        X.append(data[i : i + seq_len])\n",
    "        y.append(data[i + seq_len : i + seq_len + pred_len])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare sequences\n",
    "X, y = create_sequences(df[\"real_consumption\"].values, SEQ_LEN, PRED_LEN)\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)"
   ],
   "id": "6ec45f80e0323652",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T05:45:55.618861Z",
     "start_time": "2025-03-07T05:45:55.610841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define split percentages\n",
    "train_ratio = 0.65  # 65% training\n",
    "test_ratio = 0.15   # 15% testing\n",
    "future_ratio = 0.20 # 20% future forecasting\n",
    "\n",
    "# Compute dataset sizes\n",
    "train_size = int(train_ratio * len(X))\n",
    "test_size = int(test_ratio * len(X))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, X_future = X_tensor[:train_size], X_tensor[train_size:train_size+test_size], X_tensor[train_size+test_size:]\n",
    "y_train, y_test, y_future = y_tensor[:train_size], y_tensor[train_size:train_size+test_size], y_tensor[train_size+test_size:]\n",
    "\n",
    "# Create DataLoaders for training and testing\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n"
   ],
   "id": "cf444de26f372046",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        return self.fc(lstm_out[:, -1, :])  # Predict only the last step\n",
    "\n",
    "INPUT_SIZE = 1\n",
    "HIDDEN_SIZE = 16\n",
    "NUM_LAYERS = 1\n",
    "OUTPUT_SIZE = PRED_LEN  # 240 predictions\n",
    "\n",
    "model = LSTMModel(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, OUTPUT_SIZE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-07T05:45:58.182405Z",
     "start_time": "2025-03-07T05:45:55.646Z"
    }
   },
   "id": "e0cb1156f1f55f88",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T05:45:58.251546Z",
     "start_time": "2025-03-07T05:45:58.224844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ],
   "id": "fefcc46063cb4c69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(1, 16, batch_first=True)\n",
       "  (fc): Linear(in_features=16, out_features=120, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-07T05:45:58.290715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch.unsqueeze(-1))\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation loss\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch.unsqueeze(-1))\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(test_loader):.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"lstm_energy_forecast.pth\")\n"
   ],
   "id": "a9a08842c2830568",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "X_sample, y_sample = next(iter(test_loader))\n",
    "X_sample, y_sample = X_sample.to(device), y_sample.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_sample.unsqueeze(-1)).cpu().numpy()\n"
   ],
   "id": "14b7efa1288c06b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_sample = scaler.inverse_transform(y_sample.cpu().numpy())\n",
    "predictions = scaler.inverse_transform(predictions)\n"
   ],
   "id": "98322f159c27169c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_sample[0], label=\"Actual\")\n",
    "plt.plot(predictions[0], label=\"Predicted\", linestyle=\"dashed\")\n",
    "plt.xlabel(\"Time Steps (3-minute intervals)\")\n",
    "plt.ylabel(\"Energy Consumption\")\n",
    "plt.legend()\n",
    "plt.title(\"LSTM Forecasting: Next 12 Hours\")\n",
    "plt.show()\n"
   ],
   "id": "69d27787c563b667"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T05:07:40.302011Z",
     "start_time": "2025-03-07T05:07:40.285049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_metrics(data=reuslts_df, real=\"real_consumption\", predicted=\"predicted_consumption_new\")\n",
    "\n",
    "data_metrics(data=reuslts_df, real=\"real_consumption\", predicted=\"predicted_consumption\")"
   ],
   "id": "9c783be5217dfee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 28.3496\n",
      "MSE: 1449.8315\n",
      "RMSE: 38.0767\n",
      "R²: 0.9768\n",
      "MAE: 83.3045\n",
      "MSE: 8800.2009\n",
      "RMSE: 93.8094\n",
      "R²: 0.8594\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": "0.9768",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-07T05:07:42.123803Z",
     "start_time": "2025-03-07T05:07:42.106518Z"
    }
   },
   "id": "ebdb53202783033e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9768"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5fecb5658323033d",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
